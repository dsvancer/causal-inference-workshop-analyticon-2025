{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76e5d8c8",
   "metadata": {},
   "source": [
    "# Machine Learning with `scikit-learn`\n",
    "\n",
    "Modern causal inference is a blend of causal theory, graphical models, mathematical statistics and machine learning. To use causal inference techniques, one needs to have a solid understanding of these fields to ensure accurate estimation of causal effects.\n",
    "\n",
    "The most popular causal ML packages in Python, including `econml`, `causallib`, `doubleml`, and `causalml`, all utilize `scikit-learn` as their backend ML library. \n",
    "\n",
    "This section is a quick introduction to fitting models with `scitkit-learn` so that we can understand how `doubleml` is used in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92763a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "sns.set_style(\"whitegrid\") \n",
    "sns.set_palette('viridis')\n",
    "plt.rcParams['axes.spines.top'] = False\n",
    "plt.rcParams['axes.spines.right'] = False\n",
    "plt.rcParams['font.family'] = 'monospace'\n",
    "\n",
    "### Machine Learning\n",
    "## Cross validation and data resampling\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "## Modeling\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "## Model Evaluation\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    precision_score, \n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    classification_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afc48df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load observational dataset\n",
    "observational_df = pd.read_pickle('../data/observational_df.pkl').drop(columns=['upsell_marketing'])\n",
    "\n",
    "# Identify columns\n",
    "customer_features = observational_df.drop(columns=['amu_signup']).columns.to_list()\n",
    "target_outcome = 'amu_signup'\n",
    "\n",
    "print('Customer Features: ', customer_features)\n",
    "\n",
    "observational_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99dd4ebe",
   "metadata": {},
   "source": [
    "## Basic Machine Learning Workflow\n",
    "Below is a commonly used workflow for training machine learning algorithms. The key to randomly split our dataset into a training and test set to ensure optimal performance on new datasets\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "<img \n",
    "  src=\"../assets/model_process.png\" \n",
    "  alt=\"Modeling Process\" \n",
    "  style=\"width:auto;height:300px;\"\n",
    "> \n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2d8a2f",
   "metadata": {},
   "source": [
    "## Data Resampling\n",
    "Splitting our data into a training and test set is important for evaluating model performance and estimating generalization to new data\n",
    "\n",
    "- **Under-fitting**\n",
    "    - Model can't capture complex trends in the data\n",
    "    - Give away - poor performance on both training and test datasets\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<center>\n",
    "<img \n",
    "  src=\"../assets/under_fitting.png\" \n",
    "  alt=\"Underfitting\" \n",
    "  style=\"width:auto;height:375px;\"\n",
    "> \n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa66bd8b",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "- **Over-fitting**\n",
    "    - Model finds trends that don't exist\n",
    "    - Give away - great performance training data and *poor performance test dataset*\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<center>\n",
    "<img \n",
    "  src=\"../assets/under_fitting.png\" \n",
    "  alt=\"Underfitting\" \n",
    "  style=\"width:auto;height:375px;\"\n",
    "> \n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d223df1",
   "metadata": {},
   "source": [
    "### Optimal Complexity\n",
    "\n",
    "Generally, as we go from simple models to more complex:\n",
    "- Training error continues to decrease (potentially reaching zero!)\n",
    "- Test error decreases initially, but increases when we are over-fitting\n",
    "- Goal is to find the optimal model complexity to ensure good performance on new data\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<center>\n",
    "<img \n",
    "  src=\"../assets/optimal_complexity.png\" \n",
    "  alt=\"Underfitting\" \n",
    "  style=\"width:auto;height:375px;\"\n",
    "> \n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f6b18f",
   "metadata": {},
   "source": [
    "### Creating Training and Test Datasets with `scikit-learn`\n",
    "The `train_test_split` function can randomly divide our original dataset into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d5984e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(\n",
    "    observational_df, \n",
    "    train_size = 0.7, \n",
    "    stratify=observational_df[target_outcome])\n",
    "\n",
    "# Check dataset properties\n",
    "print(\n",
    "    f'Training Rows: {train_df.shape[0]:,}',\n",
    "    f'Training Signup Rate: {train_df[target_outcome].mean():.1%}',\n",
    "    f'Test Rows: {test_df.shape[0]:,}',\n",
    "    f'Test Signup Rate: {test_df[target_outcome].mean():.1%}',\n",
    "    sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a90570",
   "metadata": {},
   "source": [
    "## Modeling with `scikit-learn`\n",
    "\n",
    "### Introduction to Classification\n",
    "\n",
    "In classification, we are predicting a target outcome with categorical values. Typically the category of interest which we are predicting is labeled as the **positive class**. \n",
    "\n",
    "The positive class for our data would be 1. indicating a signup. The remaining outcome category is the negative class (0 in our data).\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "<img \n",
    "  src=\"../assets/classification.png\" \n",
    "  alt=\"Classification\" \n",
    "  style=\"width:auto;height:400px;\"\n",
    "> \n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05de154e",
   "metadata": {},
   "source": [
    "#### Finding the Optimal Decision Boundary\n",
    "\n",
    "The goal of classification is to find an optimal decision boundary which splits the feature space into two distinct regions, one where we predict the positive class and the other the negative class. \n",
    "\n",
    "The decision boundary is a function where the estimated probability of the positive outcome is equal to 0.5. \n",
    "\n",
    "Feature combinations above this line have $Prob(Outcome = Positive \\hspace{0.5em} class) > 0.5$ and are classified as a positive outcome.\n",
    "\n",
    "The decision boundary below is a linear boundary. Models such as **Logistic Regression** form linear decision boundaries.\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "<img \n",
    "  src=\"../assets/classification_boundary.png\" \n",
    "  alt=\"Classification Boundary\" \n",
    "  style=\"width:auto;height:400px;\"\n",
    "> \n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f8787c",
   "metadata": {},
   "source": [
    "The great about `scikit-learn` is that each model is defined as its own object with `fit()` and `predict()` methods. Once a model has been specified, then the syntax for training and performance evaluation remains the same.\n",
    "\n",
    "Another benefit of using `scikit-learn` for machine learning is its amazing [documentation](https://scikit-learn.org/stable/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38eba793",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1eedbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model object\n",
    "logistic_model = LogisticRegression()\n",
    "\n",
    "# Train with the fit() method\n",
    "logistic_model.fit(\n",
    "    X=train_df[customer_features],\n",
    "    y=train_df[target_outcome]\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76dd10a",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "We can now use our trained logistic regression model to generate predictions. In classification, we are interested in two types of output:\n",
    "- The estimated probability score for each class of the target variable\n",
    "    - This would be the estimated probability of a 1 and 0 outcome in our data (`amu_signup`)\n",
    "    - This is done with the `predict_proba()` method\n",
    "- Predicted target outcomes\n",
    "    - This would be an array of 1s and 0s based on a probability threshold or cut-off value (default is 0.5)\n",
    "    - This done with the `predict()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8add0c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicted outcome values\n",
    "logistic_model.predict(\n",
    "    X=train_df[customer_features])[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b76b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimated probabilities for each possible outcome [0, 1] order\n",
    "logistic_model.predict_proba(\n",
    "    X=train_df[customer_features])[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d0defb",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "How do we know which target outcome category each column corresponds to in the `predict_proba()` output?\n",
    "We have to use the `.class_` attritube of our trained logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782b5ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_model.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3962ca8",
   "metadata": {},
   "source": [
    "### Model Evaluation\n",
    "\n",
    "Let's combine our original test dataset and the model predictions into a single data frame. This would be usefully for detailed analysis of our model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c845d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_results_log = (\n",
    "    test_df\n",
    "    .assign(\n",
    "        amu_signup_predicted=logistic_model.predict(X=test_df[customer_features]),\n",
    "        prob_0=logistic_model.predict_proba(X=test_df[customer_features])[:, 0],\n",
    "        prob_1=logistic_model.predict_proba(X=test_df[customer_features])[:, 1],\n",
    "    )\n",
    ")\n",
    "\n",
    "test_df_results_log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4113b74",
   "metadata": {},
   "source": [
    "### Confusion Matrix\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "<img \n",
    "  src=\"../assets/confusion_matrix_1.png\" \n",
    "  style=\"width:auto;height:350px;\"\n",
    "> \n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<center>\n",
    "<img \n",
    "  src=\"../assets/confusion_matrix_2.png\"  \n",
    "  style=\"width:auto;height:220px;\"\n",
    "> \n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b12523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix \n",
    "confusion_matrix(\n",
    "    y_true=test_df_results_log['amu_signup'],\n",
    "    y_pred=test_df_results_log['amu_signup_predicted'],\n",
    "    labels=[1, 0] # Order the rows and columns\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb6a3e6",
   "metadata": {},
   "source": [
    "#### Recall\n",
    "\n",
    "To remember the meaning of this metric:\n",
    "- Recall starts with an \"R\"\n",
    "- Model accuracy for the \"real\" positive outcomes\n",
    "    - For us this is the model accuracy among the customers who **actually signed up**\n",
    "    - Equal to 0/(0 + 197) = 0 (from our confusion matrix above)\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "<img \n",
    "  src=\"../assets/recall.png\" \n",
    "  style=\"width:auto;height:350px;\"\n",
    "> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6c4041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With scikit-learn\n",
    "recall_score(\n",
    "    y_true=test_df_results_log['amu_signup'],\n",
    "    y_pred=test_df_results_log['amu_signup_predicted'],\n",
    "    pos_label=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78c5bf2",
   "metadata": {},
   "source": [
    "#### Precision\n",
    "\n",
    "To remember the meaning of this metric:\n",
    "- Precision starts with an \"P\"\n",
    "- Model accuracy for the \"predicted\" positive outcomes\n",
    "    - For us this is the model accuracy among the customers who were **predicted to purchase a product**\n",
    "    - Equal to 0 (from our confusion matrix above) since our model did not classify anybody as positive\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "<img \n",
    "  src=\"../assets/precision.png\" \n",
    "  style=\"width:auto;height:350px;\"\n",
    "> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe01951",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score(\n",
    "    y_true=test_df_results_log['amu_signup'],\n",
    "    y_pred=test_df_results_log['amu_signup_predicted'],\n",
    "    pos_label=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252027ee",
   "metadata": {},
   "source": [
    "#### F-1 Score\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "<img \n",
    "  src=\"../assets/f1_score.png\" \n",
    "  style=\"width:auto;height:330px;\"\n",
    "> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c10a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(\n",
    "    y_true=test_df_results_log['amu_signup'],\n",
    "    y_pred=test_df_results_log['amu_signup_predicted'],\n",
    "    pos_label=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ce67e9",
   "metadata": {},
   "source": [
    "### Model Performance Within Each Outcome Class\n",
    "\n",
    "It is also important to look at precision, recall, and f-1 **within** each outcome category. This is done with the `classification_report()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6b0293",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    classification_report(\n",
    "        y_true=test_df_results_log['amu_signup'],\n",
    "        y_pred=test_df_results_log['amu_signup_predicted'],\n",
    "        labels=[0, 1] # Row order\n",
    "        )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e69d46",
   "metadata": {},
   "source": [
    "### Random Forest Classifier\n",
    "Could we get better performance with a more complex ML algorithm? Let's try a random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f5a577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model object\n",
    "rf_model = RandomForestClassifier(\n",
    "    class_weight='balanced_subsample',\n",
    "    min_samples_split=10,\n",
    "    n_estimators=500\n",
    ")\n",
    "\n",
    "# Train with the fit() method\n",
    "rf_model.fit(\n",
    "    X=train_df[customer_features],\n",
    "    y=train_df[target_outcome]\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a699340",
   "metadata": {},
   "source": [
    "Looks like we are moving in the right direction! For our double machine learning work, we'll use a Random Forest classifier for our \"Outcome Model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bd274c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance on the test data\n",
    "print(\n",
    "    classification_report(\n",
    "        y_true=test_df[target_outcome],\n",
    "        y_pred=rf_model.predict(test_df[customer_features]),\n",
    "        labels=[0, 1] # Row order\n",
    "        )\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.10.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
